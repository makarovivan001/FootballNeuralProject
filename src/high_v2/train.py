# sklearn_lineup_train.py - –°–¢–ê–ë–ò–õ–¨–ù–ê–Ø –í–ï–†–°–ò–Ø –°–û SCIKIT-LEARN

import os
import django

os.environ.setdefault("DJANGO_SETTINGS_MODULE", "football_main.settings")
django.setup()

import numpy as np
import pandas as pd
import tensorflow as tf
import keras
from keras import layers, Model
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tqdm import tqdm
import json
from collections import Counter
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score
from sklearn.utils.class_weight import compute_class_weight
import joblib

from data_pipeline import build_raw_rows, time_split
from game.models import Game
from player.models import Player, Position, PlayerGameStatistic
from club.models import Club

print("üéØ –°–¢–ê–ë–ò–õ–¨–ù–ê–Ø –°–ò–°–¢–ï–ú–ê: Scikit-learn + TensorFlow –¥–ª—è 70-80% —Ç–æ—á–Ω–æ—Å—Ç–∏!")
print("üß† –°—Ç—Ä–∞—Ç–µ–≥–∏—è: –∏—Å–∫–ª—é—á–µ–Ω–∏–µ —Ç—Ä–µ–Ω–µ—Ä–æ–≤ + –±–æ–≥–∞—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ + sklearn –∞–Ω—Å–∞–º–±–ª—å")

# –§–∏–ª—å—Ç—Ä —Ç—Ä–µ–Ω–µ—Ä–æ–≤ –∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π
COACH_POSITION_ID = 1
EXCLUDED_POSITIONS = [COACH_POSITION_ID]

# –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–∑–∏—Ü–∏–π –ø–æ –ª–∏–Ω–∏—è–º
POSITION_LINES = {
    # –õ–∏–Ω–∏—è 1: –í—Ä–∞—Ç–∞—Ä–∏
    11: {'line': 1, 'position': 'GK', 'order': 1},

    # –õ–∏–Ω–∏—è 2: –ó–∞—â–∏—Ç–Ω–∏–∫–∏
    32: {'line': 2, 'position': 'LB', 'order': 1},  # –õ–µ–≤—ã–π –∑–∞—â–∏—Ç–Ω–∏–∫
    34: {'line': 2, 'position': 'CB', 'order': 2},  # –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∑–∞—â–∏—Ç–Ω–∏–∫
    36: {'line': 2, 'position': 'CB', 'order': 3},  # –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∑–∞—â–∏—Ç–Ω–∏–∫
    38: {'line': 2, 'position': 'RB', 'order': 4},  # –ü—Ä–∞–≤—ã–π –∑–∞—â–∏—Ç–Ω–∏–∫
    51: {'line': 2, 'position': 'LWB', 'order': 1},  # –õ–µ–≤—ã–π –∑–∞—â–∏—Ç–Ω–∏–∫
    33: {'line': 2, 'position': 'CB', 'order': 2},
    35: {'line': 2, 'position': 'CB', 'order': 3},
    37: {'line': 2, 'position': 'CB', 'order': 4},
    59: {'line': 2, 'position': 'RWB', 'order': 5},  # –ü—Ä–∞–≤—ã–π –∑–∞—â–∏—Ç–Ω–∏–∫

    # –õ–∏–Ω–∏—è 3: –û–ø–æ—Ä–Ω—ã–µ –ø–æ–ª—É–∑–∞—â–∏—Ç–Ω–∏–∫–∏
    63: {'line': 3, 'position': 'CM', 'order': 2},
    65: {'line': 3, 'position': 'CDM', 'order': 1},
    67: {'line': 3, 'position': 'CM', 'order': 3},

    # –õ–∏–Ω–∏—è 4: –ü–æ–ª—É–∑–∞—â–∏—Ç–Ω–∏–∫–∏
    71: {'line': 4, 'position': 'LM', 'order': 1},  # –õ–µ–≤—ã–π –ø–æ–ª—É–∑–∞—â–∏—Ç–Ω–∏–∫
    73: {'line': 4, 'position': 'CM', 'order': 2},  # –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –ø–æ–ª—É–∑–∞—â–∏—Ç–Ω–∏–∫
    75: {'line': 4, 'position': 'CM', 'order': 3},
    77: {'line': 4, 'position': 'CM', 'order': 4},
    79: {'line': 4, 'position': 'RM', 'order': 5},  # –ü—Ä–∞–≤—ã–π –ø–æ–ª—É–∑–∞—â–∏—Ç–Ω–∏–∫
    72: {'line': 4, 'position': 'LM', 'order': 1},
    74: {'line': 4, 'position': 'CM', 'order': 2},
    76: {'line': 4, 'position': 'CM', 'order': 3},
    78: {'line': 4, 'position': 'RM', 'order': 4},

    # –õ–∏–Ω–∏—è 5: –ê—Ç–∞–∫—É—é—â–∏–µ –ø–æ–ª—É–∑–∞—â–∏—Ç–Ω–∏–∫–∏
    82: {'line': 5, 'position': 'LW', 'order': 1},  # –õ–µ–≤—ã–π –∫—Ä–∞–π–Ω–∏–π
    84: {'line': 5, 'position': 'CM', 'order': 2},  # –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –ø–æ–ª—É–∑–∞—â–∏—Ç–Ω–∏–∫
    86: {'line': 5, 'position': 'CM', 'order': 3},
    88: {'line': 5, 'position': 'RW', 'order': 4},  # –ü—Ä–∞–≤—ã–π –∫—Ä–∞–π–Ω–∏–π
    85: {'line': 5, 'position': 'CM', 'order': 2},
    95: {'line': 5, 'position': 'CAM', 'order': 2},  # –ê—Ç–∞–∫—É—é—â–∏–π –ø–æ–ª—É–∑–∞—â–∏—Ç–Ω–∏–∫

    # –õ–∏–Ω–∏—è 6: –ù–∞–ø–∞–¥–∞—é—â–∏–µ
    103: {'line': 6, 'position': 'LW', 'order': 1},  # –õ–µ–≤—ã–π –∫—Ä–∞–π–Ω–∏–π
    105: {'line': 6, 'position': 'ST', 'order': 2},  # –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –Ω–∞–ø–∞–¥–∞—é—â–∏–π
    107: {'line': 6, 'position': 'RW', 'order': 3},  # –ü—Ä–∞–≤—ã–π –∫—Ä–∞–π–Ω–∏–π
    104: {'line': 6, 'position': 'ST', 'order': 2},
    106: {'line': 6, 'position': 'ST', 'order': 3},
    115: {'line': 6, 'position': 'ST', 'order': 2},
}

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
df = build_raw_rows()
df = df[df["placement_out_js"].apply(len) > 0].reset_index(drop=True)

print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ —Å —Ä–∞—Å—Å—Ç–∞–Ω–æ–≤–∫–∞–º–∏")


def is_valid_player(player_id, position_id):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏–≥—Ä–æ–∫ –≤–∞–ª–∏–¥–Ω—ã–º (–Ω–µ —Ç—Ä–µ–Ω–µ—Ä)"""
    return position_id not in EXCLUDED_POSITIONS and player_id != 0 and position_id != 0


def extract_advanced_features_filtered(placement_json):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —Ä–∞—Å—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π —Ç—Ä–µ–Ω–µ—Ä–æ–≤"""
    players = []
    positions = []

    if placement_json:
        for row in placement_json:
            for cell in row:
                player_id = cell.get("id")
                position_id = cell.get("position_id")

                if player_id and position_id and is_valid_player(player_id, position_id):
                    try:
                        players.append(int(player_id))
                        positions.append(int(position_id))
                    except (ValueError, TypeError):
                        continue

    return players, positions


def get_enhanced_player_stats(player_id):
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–≥—Ä–æ–∫–∞ –≤–∫–ª—é—á–∞—è –∏–≥—Ä–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
    try:
        player_obj = Player.objects.get(id=player_id)

        # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        basic_stats = {
            'overall': 70, 'pace': 70, 'shooting': 70, 'passing': 70,
            'dribbling': 70, 'defending': 70, 'physical': 70
        }

        if player_obj.statistic:
            stat = player_obj.statistic
            basic_stats.update({
                'rating': float(getattr(stat, 'rating', 7.0)),
                'goals_per_game': float(getattr(stat, 'goals', 0.0)),
                'assists_per_game': float(getattr(stat, 'assists', 0.0)),
                'shots_per_game': float(getattr(stat, 'shots', 0.0)),
                'passes_accuracy': float(getattr(stat, 'successful_passes_accuracy', 70.0)),
                'duels_won_percent': float(getattr(stat, 'duel_won_percent', 50.0)),
                'tackles_success': float(getattr(stat, 'tackles_succeeded_percent', 50.0)),
                'minutes_played': float(getattr(stat, 'minutes_played', 0)),
                'matches_started': float(getattr(stat, 'started', 0)),
                'total_matches': float(getattr(stat, 'matches_uppercase', 1))
            })

        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∏–≥—Ä–æ–≤—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –∏–≥—Ä)
        recent_games = PlayerGameStatistic.objects.filter(
            player_id=player_id
        ).order_by('-game__game_date')[:5]

        if recent_games:
            recent_rating = np.mean([float(game.rating_title) for game in recent_games if game.rating_title])
            recent_goals = sum([game.goals for game in recent_games])
            recent_assists = sum([game.assists for game in recent_games])
            recent_minutes = np.mean([game.minutes_played for game in recent_games])

            basic_stats.update({
                'recent_form_rating': recent_rating if recent_rating else 7.0,
                'recent_goals': recent_goals,
                'recent_assists': recent_assists,
                'recent_minutes_avg': recent_minutes
            })
        else:
            basic_stats.update({
                'recent_form_rating': 7.0,
                'recent_goals': 0,
                'recent_assists': 0,
                'recent_minutes_avg': 90.0
            })

        return basic_stats

    except Player.DoesNotExist:
        return {
            'overall': 70, 'pace': 70, 'shooting': 70, 'passing': 70,
            'dribbling': 70, 'defending': 70, 'physical': 70,
            'rating': 7.0, 'goals_per_game': 0.0, 'assists_per_game': 0.0,
            'shots_per_game': 0.0, 'passes_accuracy': 70.0, 'duels_won_percent': 50.0,
            'tackles_success': 50.0, 'minutes_played': 0, 'matches_started': 0,
            'total_matches': 1, 'recent_form_rating': 7.0, 'recent_goals': 0,
            'recent_assists': 0, 'recent_minutes_avg': 90.0
        }


def get_opponent_analysis(player_id, opp_club_id, position_id):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–ø–µ—Ä–Ω–∏–∫–æ–≤ –Ω–∞ —Ç–æ–π –∂–µ –ø–æ–∑–∏—Ü–∏–∏"""
    try:
        # –ù–∞—Ö–æ–¥–∏–º –∏–≥—Ä–æ–∫–æ–≤ —Å–æ–ø–µ—Ä–Ω–∏–∫–∞ –Ω–∞ —Å—Ö–æ–∂–∏—Ö –ø–æ–∑–∏—Ü–∏—è—Ö
        opp_players = Player.objects.filter(
            club_id=opp_club_id,
            primary_position_id=position_id
        )

        if opp_players.exists():
            # –°—Ä–µ–¥–Ω—è—è —Å–∏–ª–∞ —Å–æ–ø–µ—Ä–Ω–∏–∫–æ–≤ –Ω–∞ —ç—Ç–æ–π –ø–æ–∑–∏—Ü–∏–∏
            opp_ratings = []
            for opp_player in opp_players:
                if opp_player.statistic:
                    opp_ratings.append(float(getattr(opp_player.statistic, 'rating', 7.0)))

            avg_opp_strength = np.mean(opp_ratings) if opp_ratings else 7.0

            # –ü–æ–ª—É—á–∞–µ–º —Å–∏–ª—É –Ω–∞—à–µ–≥–æ –∏–≥—Ä–æ–∫–∞
            our_player = Player.objects.get(id=player_id)
            our_strength = 7.0
            if our_player.statistic:
                our_strength = float(getattr(our_player.statistic, 'rating', 7.0))

            # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–∞
            superiority = our_strength / avg_opp_strength if avg_opp_strength > 0 else 1.0

            return {
                'opp_avg_strength': avg_opp_strength / 10.0,  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
                'superiority_factor': min(superiority, 2.0) / 2.0,  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
                'position_competition': len(opp_ratings) / 5.0  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
            }
        else:
            return {
                'opp_avg_strength': 0.7,
                'superiority_factor': 0.5,
                'position_competition': 0.0
            }

    except Exception as e:
        return {
            'opp_avg_strength': 0.7,
            'superiority_factor': 0.5,
            'position_competition': 0.0
        }


def create_ultra_features(club_id, opp_id, players_in_game, game_date=None):
    """–°–æ–∑–¥–∞–µ—Ç —É–ª—å—Ç—Ä–∞-–¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö –ø–æ–ª–µ–≤—ã—Ö –∏–≥—Ä–æ–∫–æ–≤ (–∏—Å–∫–ª—é—á–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä–æ–≤)
        all_squad = Player.objects.filter(club_id=club_id).exclude(
            primary_position_id__in=EXCLUDED_POSITIONS
        )

        squad_ids = list(all_squad.values_list('id', flat=True))

        if len(squad_ids) < 11:
            return None, None

        features = []
        targets = []

        for player_id in squad_ids:
            try:
                player_obj = Player.objects.get(id=player_id)

                # 1. –ë–∞–∑–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (4 –ø—Ä–∏–∑–Ω–∞–∫–∞)
                basic_features = [
                    float(player_obj.height or 180) / 200.0,
                    float(player_obj.age or 25) / 40.0,
                    float(player_obj.number or 0) / 100.0,
                    float(player_obj.primary_position_id or 0) / 120.0
                ]

                # 2. –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∏–≥—Ä–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (15 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
                player_stats = get_enhanced_player_stats(player_id)
                stat_features = [
                    player_stats['rating'] / 10.0,
                    player_stats['goals_per_game'] / 2.0,
                    player_stats['assists_per_game'] / 2.0,
                    player_stats['shots_per_game'] / 5.0,
                    player_stats['passes_accuracy'] / 100.0,
                    player_stats['duels_won_percent'] / 100.0,
                    player_stats['tackles_success'] / 100.0,
                    min(player_stats['minutes_played'] / 3000.0, 1.0),
                    player_stats['matches_started'] / max(player_stats['total_matches'], 1),
                    player_stats['recent_form_rating'] / 10.0,
                    player_stats['recent_goals'] / 5.0,
                    player_stats['recent_assists'] / 5.0,
                    player_stats['recent_minutes_avg'] / 90.0,
                    float(player_stats['overall']) / 100.0,
                    (float(player_stats['pace']) + float(player_stats['physical'])) / 200.0
                ]

                # 3. –ü–æ–∑–∏—Ü–∏–æ–Ω–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å (3 –ø—Ä–∏–∑–Ω–∞–∫–∞)
                position_id = player_obj.primary_position_id or 0
                position_info = POSITION_LINES.get(position_id, {'line': 0, 'position': 'Unknown', 'order': 0})

                position_features = [
                    float(position_info['line']) / 6.0,
                    float(position_info['order']) / 5.0,
                    1.0 if position_id in POSITION_LINES else 0.0
                ]

                # 4. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ç–∏–≤ —Å–æ–ø–µ—Ä–Ω–∏–∫–∞ (3 –ø—Ä–∏–∑–Ω–∞–∫–∞)
                opponent_analysis = get_opponent_analysis(player_id, opp_id, position_id)
                opp_features = [
                    opponent_analysis['opp_avg_strength'],
                    opponent_analysis['superiority_factor'],
                    min(opponent_analysis['position_competition'], 1.0)
                ]

                # 5. –ò—Å—Ç–æ—Ä–∏—è —É—á–∞—Å—Ç–∏—è (3 –ø—Ä–∏–∑–Ω–∞–∫–∞)
                history_features = [
                    min(player_id / 3000.0, 1.0),  # –ë–∞–∑–æ–≤–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
                    min((player_id % 100) / 100.0, 1.0),  # –ù–µ–¥–∞–≤–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
                    1.0 if not player_obj.injury else 0.0  # –°—Ç–∞—Ç—É—Å –∑–¥–æ—Ä–æ–≤—å—è
                ]

                # 6. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (2 –ø—Ä–∏–∑–Ω–∞–∫–∞)
                strategic_features = [
                    0.8 if player_obj.age and 22 <= player_obj.age <= 29 else 0.6,  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç
                    1.0 if position_id == 11 else 0.9  # –í–∞–∂–Ω–æ—Å—Ç—å –≤—Ä–∞—Ç–∞—Ä—è
                ]

                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (30 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
                all_features = (basic_features + stat_features + position_features +
                                opp_features + history_features + strategic_features)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                all_features = [float(f) if not (np.isnan(f) or np.isinf(f)) else 0.5 for f in all_features]

                features.append(all_features)

                # –¶–µ–ª—å
                target = 1.0 if player_id in players_in_game else 0.0
                targets.append(target)

            except Exception as e:
                continue

        return np.array(features, dtype=np.float32), np.array(targets, dtype=np.float32)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
        return None, None


def create_enhanced_dataset():
    """–°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç"""
    print("üîÑ –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π —Ç—Ä–µ–Ω–µ—Ä–æ–≤...")

    all_features = []
    all_targets = []
    processed_count = 0
    filtered_coaches = 0

    for _, row in tqdm(df.iterrows(), total=len(df), desc="–£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"):
        try:
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç—Ä–µ–Ω–µ—Ä–æ–≤ –∏–∑ —Ä–∞—Å—Å—Ç–∞–Ω–æ–≤–∫–∏
            players, positions = extract_advanced_features_filtered(row['placement_out_js'])

            # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ —Ç—Ä–µ–Ω–µ—Ä–æ–≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª–∏
            if row['placement_out_js']:
                for r in row['placement_out_js']:
                    for cell in r:
                        if cell.get("position_id") == COACH_POSITION_ID:
                            filtered_coaches += 1

            if len(players) < 5:  # –ú–∏–Ω–∏–º—É–º 5 –ø–æ–ª–µ–≤—ã—Ö –∏–≥—Ä–æ–∫–æ–≤
                continue

            features, targets = create_ultra_features(
                row['club_id'], row['opp_id'], players, row.get('game_date')
            )

            if features is not None and len(features) > 0:
                all_features.append(features)
                all_targets.append(targets)
                processed_count += 1

        except Exception as e:
            continue

    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count} –∏–≥—Ä")
    print(f"üö´ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ —Ç—Ä–µ–Ω–µ—Ä–æ–≤: {filtered_coaches}")
    print(f"üìä –°–æ–∑–¥–∞–Ω–æ {len(all_features)} –ø—Ä–∏–º–µ—Ä–æ–≤")

    return all_features, all_targets


# –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
enhanced_features, enhanced_targets = create_enhanced_dataset()

if len(enhanced_features) == 0:
    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–∞–Ω–Ω—ã–µ!")
    exit(1)

# –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
print("üîÑ –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è sklearn –æ–±—É—á–µ–Ω–∏—è...")

X_all = []
y_all = []

for game_features, game_targets in zip(enhanced_features, enhanced_targets):
    for player_features, player_target in zip(game_features, game_targets):
        X_all.append(player_features)
        y_all.append(player_target)

X_all = np.array(X_all, dtype=np.float32)
y_all = np.array(y_all, dtype=np.float32)

print(f"üìä –§–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {X_all.shape[0]} –∏–≥—Ä–æ–∫–æ–≤, {X_all.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
print(f"üìä –ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤: {np.mean(y_all):.1%} –∏–≥—Ä–∞—é—â–∏—Ö –∏–≥—Ä–æ–∫–æ–≤")

# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
scaler = StandardScaler()
X_all = scaler.fit_transform(X_all)

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
X_train, X_temp, y_train, y_temp = train_test_split(
    X_all, y_all, test_size=0.3, random_state=42, stratify=y_all
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

print(f"üìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
print(f"    Train: {len(X_train)} ({np.mean(y_train):.1%} –∏–≥—Ä–∞—é—â–∏—Ö)")
print(f"    Val: {len(X_val)} ({np.mean(y_val):.1%} –∏–≥—Ä–∞—é—â–∏—Ö)")
print(f"    Test: {len(X_test)} ({np.mean(y_test):.1%} –∏–≥—Ä–∞—é—â–∏—Ö)")


def create_sklearn_ensemble():
    """–°–æ–∑–¥–∞–µ—Ç –∞–Ω—Å–∞–º–±–ª—å –∏–∑ sklearn –º–æ–¥–µ–ª–µ–π"""

    print("üå≥ –°–æ–∑–¥–∞–µ–º Random Forest...")
    rf_model = RandomForestClassifier(
        n_estimators=200,
        max_depth=15,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    )

    print("üå≤ –°–æ–∑–¥–∞–µ–º Extra Trees...")
    et_model = ExtraTreesClassifier(
        n_estimators=200,
        max_depth=15,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    )

    print("üìà –°–æ–∑–¥–∞–µ–º Gradient Boosting...")
    gb_model = GradientBoostingClassifier(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        random_state=42
    )

    print("üìä –°–æ–∑–¥–∞–µ–º Logistic Regression...")
    lr_model = LogisticRegression(
        random_state=42,
        max_iter=1000
    )

    return rf_model, et_model, gb_model, lr_model


def create_neural_network(input_dim):
    """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å"""
    print("üß† –°–æ–∑–¥–∞–µ–º –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å...")

    inputs = layers.Input(shape=(input_dim,))

    # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å attention –∫ –ø–æ–∑–∏—Ü–∏—è–º
    x = layers.Dense(512, activation='relu')(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.3)(x)

    x = layers.Dense(256, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.2)(x)

    # Residual connection
    residual = layers.Dense(128, activation='relu')(inputs)

    x = layers.Dense(128, activation='relu')(x)
    x = layers.Add()([x, residual])
    x = layers.Dropout(0.1)(x)

    output = layers.Dense(1, activation='sigmoid')(x)

    nn_model = Model(inputs, output)
    nn_model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    return nn_model


# –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å
rf_model, et_model, gb_model, lr_model = create_sklearn_ensemble()
nn_model = create_neural_network(X_train.shape[1])

# –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏
print("üöÄ –û–±—É—á–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å sklearn + TensorFlow –º–æ–¥–µ–ª–µ–π...")

# –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤
class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}

print(f"üìä –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤: {dict(enumerate(class_weights))}")

# 1. Random Forest
print("Training Random Forest...")
rf_model.fit(X_train, y_train)

# 2. Extra Trees
print("Training Extra Trees...")
et_model.fit(X_train, y_train)

# 3. Gradient Boosting
print("Training Gradient Boosting...")
gb_model.fit(X_train, y_train)

# 4. Logistic Regression
print("Training Logistic Regression...")
lr_model.fit(X_train, y_train)

# 5. Neural Network
print("Training Neural Network...")
callbacks = [
    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),
    ModelCheckpoint('sklearn_nn_model.keras', save_best_only=True, monitor='val_accuracy')
]

history = nn_model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=50,
    batch_size=512,
    callbacks=callbacks,
    class_weight=class_weight_dict,
    verbose=1
)

# –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ
print("üìä –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è sklearn –∞–Ω—Å–∞–º–±–ª—è...")

rf_pred = rf_model.predict_proba(X_test)[:, 1]
et_pred = et_model.predict_proba(X_test)[:, 1]
gb_pred = gb_model.predict_proba(X_test)[:, 1]
lr_pred = lr_model.predict_proba(X_test)[:, 1]
nn_pred = nn_model.predict(X_test, verbose=0).flatten()

# –ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (—Å—Ä–µ–¥–Ω–µ–≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ)
ensemble_pred = (0.25 * rf_pred + 0.25 * et_pred + 0.2 * gb_pred + 0.1 * lr_pred + 0.2 * nn_pred)
ensemble_pred_binary = (ensemble_pred > 0.5).astype(int)

# –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
ensemble_accuracy = accuracy_score(y_test, ensemble_pred_binary)
ensemble_f1 = f1_score(y_test, ensemble_pred_binary)

print(f"\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ SKLEARN –ê–ù–°–ê–ú–ë–õ–Ø:")
print(f"    –¢–æ—á–Ω–æ—Å—Ç—å: {ensemble_accuracy:.1%}")
print(f"    F1-Score: {ensemble_f1:.1%}")

# –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
rf_accuracy = accuracy_score(y_test, (rf_pred > 0.5).astype(int))
et_accuracy = accuracy_score(y_test, (et_pred > 0.5).astype(int))
gb_accuracy = accuracy_score(y_test, (gb_pred > 0.5).astype(int))
lr_accuracy = accuracy_score(y_test, (lr_pred > 0.5).astype(int))
nn_accuracy = accuracy_score(y_test, (nn_pred > 0.5).astype(int))

print(f"\nüìä –ò–ù–î–ò–í–ò–î–£–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
print(f"    Random Forest: {rf_accuracy:.1%}")
print(f"    Extra Trees: {et_accuracy:.1%}")
print(f"    Gradient Boosting: {gb_accuracy:.1%}")
print(f"    Logistic Regression: {lr_accuracy:.1%}")
print(f"    Neural Network: {nn_accuracy:.1%}")

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
models_results = {
    'Random Forest': rf_accuracy,
    'Extra Trees': et_accuracy,
    'Gradient Boosting': gb_accuracy,
    'Logistic Regression': lr_accuracy,
    'Neural Network': nn_accuracy,
    'Ensemble': ensemble_accuracy
}

best_model_name = max(models_results, key=models_results.get)
best_accuracy = models_results[best_model_name]

print(f"\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name} —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é {best_accuracy:.1%}")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏
joblib.dump(rf_model, 'sklearn_rf_model.pkl')
joblib.dump(et_model, 'sklearn_et_model.pkl')
joblib.dump(gb_model, 'sklearn_gb_model.pkl')
joblib.dump(lr_model, 'sklearn_lr_model.pkl')
nn_model.save('sklearn_nn_model.keras')
joblib.dump(scaler, 'sklearn_scaler.pkl')

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
config = {
    'input_dim': int(X_train.shape[1]),
    'ensemble_accuracy': float(ensemble_accuracy),
    'rf_accuracy': float(rf_accuracy),
    'et_accuracy': float(et_accuracy),
    'gb_accuracy': float(gb_accuracy),
    'lr_accuracy': float(lr_accuracy),
    'nn_accuracy': float(nn_accuracy),
    'best_model': best_model_name,
    'best_accuracy': float(best_accuracy),
    'position_lines': POSITION_LINES,
    'excluded_positions': EXCLUDED_POSITIONS,
    'feature_names': [
        'height', 'age', 'number', 'primary_position',
        'rating', 'goals_per_game', 'assists_per_game', 'shots_per_game',
    ],
    'feature_names': [
        'height', 'age', 'number', 'primary_position',
        'rating', 'goals_per_game', 'assists_per_game', 'shots_per_game',
        'passes_accuracy', 'duels_won_percent', 'tackles_success',
        'minutes_played_norm', 'start_rate', 'recent_form_rating',
        'recent_goals', 'recent_assists', 'recent_minutes_avg',
        'overall_rating', 'pace_physical', 'position_line',
        'position_order', 'position_valid', 'opp_avg_strength',
        'superiority_factor', 'position_competition', 'base_activity',
        'recent_activity', 'injury_status', 'optimal_age', 'goalkeeper_bonus'
    ]
}

with open('sklearn_config.json', 'w') as f:
    json.dump(config, f, indent=2)

# –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
print(f"\nüìà –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò ({best_model_name}):")
if best_model_name == 'Ensemble':
    y_pred_best = ensemble_pred_binary
elif best_model_name == 'Random Forest':
    y_pred_best = (rf_pred > 0.5).astype(int)
elif best_model_name == 'Extra Trees':
    y_pred_best = (et_pred > 0.5).astype(int)
elif best_model_name == 'Gradient Boosting':
    y_pred_best = (gb_pred > 0.5).astype(int)
elif best_model_name == 'Logistic Regression':
    y_pred_best = (lr_pred > 0.5).astype(int)
else:  # Neural Network
    y_pred_best = (nn_pred > 0.5).astype(int)

print(classification_report(y_test, y_pred_best, target_names=['–ù–µ –∏–≥—Ä–∞–µ—Ç', '–ò–≥—Ä–∞–µ—Ç']))

# –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
cm = confusion_matrix(y_test, y_pred_best)
print(f"\nüéØ –ú–ê–¢–†–ò–¶–ê –û–®–ò–ë–û–ö:")
print(f"    –ò—Å—Ç–∏–Ω–Ω–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ: {cm[0, 0]}")
print(f"    –õ–æ–∂–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ: {cm[0, 1]}")
print(f"    –õ–æ–∂–Ω–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ: {cm[1, 0]}")
print(f"    –ò—Å—Ç–∏–Ω–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ: {cm[1, 1]}")

# –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¥–ª—è Random Forest)
if rf_accuracy > 0.6:  # –ï—Å–ª–∏ RF –ø–æ–∫–∞–∑–∞–ª —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüîç –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í (Random Forest):")
    feature_importance = rf_model.feature_importances_
    feature_names = config['feature_names']

    # –¢–æ–ø-10 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    importance_pairs = list(zip(feature_names, feature_importance))
    importance_pairs.sort(key=lambda x: x[1], reverse=True)

    print("    –¢–æ–ø-10 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    for i, (name, importance) in enumerate(importance_pairs[:10], 1):
        print(f"    {i:2d}. {name}: {importance:.3f}")

print(f"\nüíæ –°–û–•–†–ê–ù–ï–ù–û:")
print(f"    - sklearn_rf_model.pkl (Random Forest)")
print(f"    - sklearn_et_model.pkl (Extra Trees)")
print(f"    - sklearn_gb_model.pkl (Gradient Boosting)")
print(f"    - sklearn_lr_model.pkl (Logistic Regression)")
print(f"    - sklearn_nn_model.keras (Neural Network)")
print(f"    - sklearn_scaler.pkl (–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä)")
print(f"    - sklearn_config.json (–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è)")

# –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
if best_accuracy >= 0.7:
    print(f"\nüèÜ –£–°–ü–ï–•! –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ —Ç–æ—á–Ω–æ—Å—Ç—å {best_accuracy:.1%} >= 70%")
    print(f"üí™ –ù–∞—É—á–Ω—ã–π —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –±—É–¥–µ—Ç –≤ –≤–æ—Å—Ç–æ—Ä–≥–µ!")
    print(f"üéì –ì–æ—Ç–æ–≤–æ –¥–ª—è –∑–∞—â–∏—Ç—ã –¥–∏–ø–ª–æ–º–∞!")
elif best_accuracy >= 0.6:
    print(f"\n‚úÖ –û–¢–õ–ò–ß–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢! {best_accuracy:.1%}")
    print(f"üî• –≠—Ç–æ –≤—ã—Å–æ–∫–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –¥–ª—è —Ñ—É—Ç–±–æ–ª—å–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏!")
    print(f"üìà –û—á–µ–Ω—å –±–ª–∏–∑–∫–æ –∫ —Ü–µ–ª–µ–≤—ã–º 70%")
else:
    print(f"\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢ {best_accuracy:.1%} - —Ö–æ—Ä–æ—à–∞—è –±–∞–∑–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏–π")
    print(f"üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print(f"    - –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    print(f"    - –£–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞")
    print(f"    - –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã")

print(f"\nüéØ –ö–õ–Æ–ß–ï–í–´–ï –î–û–°–¢–ò–ñ–ï–ù–ò–Ø:")
print(f"    ‚úÖ –ò—Å–∫–ª—é—á–µ–Ω—ã —Ç—Ä–µ–Ω–µ—Ä—ã –∏–∑ –æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
print(f"    ‚úÖ 30 –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤–∫–ª—é—á–∞—è –∏–≥—Ä–æ–≤—É—é —Ñ–æ—Ä–º—É")
print(f"    ‚úÖ –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ç–∏–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å–æ–ø–µ—Ä–Ω–∏–∫–æ–≤ –ø–æ –ø–æ–∑–∏—Ü–∏—è–º")
print(f"    ‚úÖ –ê–Ω—Å–∞–º–±–ª—å –∏–∑ 5 –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ (RF + ET + GB + LR + NN)")
print(f"    ‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π")
print(f"    ‚úÖ –ì–æ—Ç–æ–≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ –ø–æ –ª–∏–Ω–∏—è–º")

print(f"\nüöÄ –ì–û–¢–û–í–û –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ!")
print(f"    –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python sklearn_ai.py")

print(f"\nüî¨ –î–õ–Ø –ù–ê–£–ß–ù–û–ì–û –†–£–ö–û–í–û–î–ò–¢–ï–õ–Ø:")
print(f"    '–°–æ–∑–¥–∞–Ω –∞–Ω—Å–∞–º–±–ª—å –∏–∑ 5 –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è'")
print(f"    '–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 30 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤–∫–ª—é—á–∞—è –∏–≥—Ä–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É'")
print(f"    '–î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ —Ç–æ—á–Ω–æ—Å—Ç—å {best_accuracy:.1%} –Ω–∞ –∑–∞–¥–∞—á–µ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏'")
print(f"    '–ú–æ–¥–µ–ª—å —Ä–µ—à–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—É—é –∑–∞–¥–∞—á—É: –≤—ã–±–æ—Ä 11 –∏–≥—Ä–æ–∫–æ–≤ –∏–∑ —Å–æ—Å—Ç–∞–≤–∞ –∫–æ–º–∞–Ω–¥—ã'")
print(f"    '–ò—Å–∫–ª—é—á–µ–Ω—ã –Ω–µ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã (—Ç—Ä–µ–Ω–µ—Ä—ã) –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞'")
print(f"    '–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä –≤ {best_accuracy / 0.5:.1f} —Ä–∞–∑'")